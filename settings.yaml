# Settings for plankton classif benchmark

# Global settings
global:
    # Reproducibility
    random_state: 12 # null for no reproducibility, any integer for reproducibility.
    
    # Input data
    input_data:
      instrument: 'isiis' # name of the instrument. 
      split: [70, 15, 15] # split for training / validation / test. Sum should equal 100.
      n_max: null # maximum number of objects in each class for training data

# Random Forest
rf:
  n_jobs: 6 # number of cores to use for random forest fitting
  use_weights: true # whether to use class weights for training
  weights: 'sqrt_i_f' # method for weights computation. 'i_f' for inverse frequency, 'sqrt_i_f' for square root of inverse frequency
  grid_search:
    go: true # whether to do a gridsearch to find optimal hyperparameters
    max_features_try: [4, 6, 8, 10] # values to try for max_features, i.e. number of features to use to compute each split (default for classification is sqrt(n_features))
    min_samples_leaf_try: [2, 5, 10] # values to try for min_samples_leaf, i.e. minimum number of samples required to be at a leaf node (default for classification is 5)
    n_estimators_try: [100, 200, 350, 500] # values to try for n_estimators, i.e. number of trees
  hyperparameters: # values have to be provided if they are not estimated with a gridsearch
    max_features: null # number of features to use to compute each split
    min_samples_leaf: null # minimum number of samples required to be at a leaf node
    n_estimators: null # number of trees

# Convolutional Neural Network
cnn:
  data:
    batch_size: 32 # size of batches
    px_del: 31 # number of pixels to delete at bottom of images (e.g. to remove a scale bar)
    preserve_size: false # whether to perserve size of organisms when images are resized for cnn input.
    # If true, small images will be padded to desired size; if false, small images will be resized to desired size. 
    augment: true # wheter to use data augmentation for training
    use_weights: true # whether to use class weights for training
    weights: 'sqrt_i_f' # method for weights computation. 'i_f' for inverse frequency, 'sqrt_i_f' for square root of inverse frequency
  
  architecture:
    fc_layers_nb: 1 # number of fully connected layers to insert between the feature extractor and the classification clayer
    fc_layers_size: 680 # size of fully connected layers
    fc_layers_dropout: 0.5 # drop-out rate for fully connected layers
    classif_layer_dropout: null # drop-out rate for fully classification layer
    train_fe: true # whether to train the feature extractor. If false, only fully connected layers and classification clayer will be trained. 
    
  compilation:
    lr_method: 'decay' # learning rate evolution. 'decay' for a decaying learning rate; 'constant' for a constant learning rate
    initial_lr: 0.001 # initial learning rate
    decay_rate: 0.97 # rate for learning rate decay
    loss: 'cce' # computation of loss. 'cce' for categorical cross entropy; 'sfce' for sigmoid focal cross entropy.

  training:
    epochs: 50 # number of epochs to train for
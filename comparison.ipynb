{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of accuracy results across datasets and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = glob.glob('output/*/test_results.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate empty dict to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'dataset': [],\n",
    "    'model': [],\n",
    "    'accuracy': [],\n",
    "    'balanced_accuracy': [],\n",
    "    'living_accuracy': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over test files and extract accuracy values for each dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_file in test_files:\n",
    "    condi = test_file.split('/')[1]\n",
    "    dataset = condi.split('_')[1]\n",
    "    model = condi.split('_')[0].upper()\n",
    "    \n",
    "    with open(test_file,'rb') as file:\n",
    "        test_results = pickle.load(file)        \n",
    "        accuracy = test_results.get('accuracy')\n",
    "        balanced_accuracy = test_results.get('balanced_accuracy')\n",
    "        living_accuracy = test_results.get('living_accuracy')\n",
    "    \n",
    "    results['dataset'].append(dataset)\n",
    "    results['model'].append(model)\n",
    "    results['accuracy'].append(accuracy)\n",
    "    results['balanced_accuracy'].append(balanced_accuracy)\n",
    "    results['living_accuracy'].append(living_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to dataframe and make columns categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results['dataset'] = pd.Categorical(results['dataset'], pd.unique(results['dataset']).tolist())\n",
    "results['model'] = pd.Categorical(results['model'], pd.unique(results['model']).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pivot(index='model', columns='dataset', values='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(results, aes(x='dataset', y='accuracy', fill='model')) + \n",
    "    geom_col(stat='identity', position='dodge') +\n",
    "    labs(fill='Model', title = 'Accuracy value per dataset per model',\n",
    "        x='Dataset', y='Accuracy')+\n",
    "    theme_classic() +\n",
    "    scale_fill_manual(values={'RF': 'lightgray', 'CNN': 'gray'})+\n",
    "    theme(axis_text_x=element_text(size=10), axis_text_y=element_text(size=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pivot(index='model', columns='dataset', values='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(results, aes(x='dataset', y='balanced_accuracy', fill='model')) + \n",
    "    geom_col(stat='identity', position='dodge') +\n",
    "    labs(fill='Model', title = 'Balanced accuracy value per dataset per model',\n",
    "        x='Dataset', y='Balanced accuracy')+\n",
    "    theme_classic() +\n",
    "    scale_fill_manual(values={'RF': 'lightgray', 'CNN': 'gray'})+\n",
    "    theme(axis_text_x=element_text(size=10), axis_text_y=element_text(size=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Living accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pivot(index='model', columns='dataset', values='living_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(results, aes(x='dataset', y='living_accuracy', fill='model')) + \n",
    "    geom_col(stat='identity', position='dodge') +\n",
    "    labs(fill='Model', title = 'Living accuracy value per dataset per model',\n",
    "        x='Dataset', y='Living accuracy')+\n",
    "    theme_classic() +\n",
    "    scale_fill_manual(values={'RF': 'lightgray', 'CNN': 'gray'})+\n",
    "    theme(axis_text_x=element_text(size=10), axis_text_y=element_text(size=10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
